# Analyses descriptives bivariées
Réaliser une analyse bivariée désigne le fait d'étudier la relation qui peut exister entre deux variables. Dans ce chapitre, nous allons voir les procédures graphiques et calculatoires qui permettent d'étudier et de quantifier le degré de relation pouvant exister entre deux variables dans les cas suivants : entre deux variables quantitatives, entre deux variables qualitatives, et entre une variable quantitative et une variable qualitative. Comme dans le chapitre précédent, l'objectif est ici d'explorer et de décrire les données et leurs relations à l'échelle d'un échantillon, sans pour autant chercher à déterminer l'incertitude qu'il peut exister dans les statistiques calculées en vue de les utiliser pour réaliser une inférence dans la population représentée.

## Relation entre deux variables quantitatives
### Etudier graphiquement la relation
Comme dans le cadre d'analyses univariées, une bonne pratique, lorsqu'on étudie une relation bivariée, est de faire un graphique. Avec des variables quantitatives, il s'agit de montrer les valeurs d'une variable en fonction des valeurs de l'autre variable, chose que permet un simple nuage de points. Plusieurs types de relations peuvent alors être rencontrés, ces relations pouvant potentiellement s'apparenter à autant de fonctions mathématiques que l'on connaît. Parmi les plus connues, on a par exemple les relations linéaires, les relations logarithmiques, ou encore les relations quadratiques, qui sont illustrées ci-dessous.

```{r relationshipsIllustrations, message = FALSE, warning = FALSE, echo = FALSE, fig.align ="center", fig.cap="Différentes formes de relation"}

# Jeu de données pour la relation linéaire
set.seed(123)
data_lin <- 
  tibble(x = rnorm(n = 500, mean = 1, sd = 3)) %>%
  mutate(y = 2 * x + rnorm(n = 500, mean = 0, sd = 1))

# Jeu de données pour la relation logarithmique
set.seed(123)
data_log <- 
  tibble(x = rnorm(n = 500, mean = 1, sd = 3)) %>%
  mutate(y = log(x) + rnorm(n = 500, mean = 0, sd = 1))

# Jeu de données pour la relation quadratique
set.seed(123)
data_quad <- 
  tibble(x = rnorm(n = 500, mean = 1, sd = 6)) %>%
  mutate(y = x ^ 2 + rnorm(n = 500, mean = 2, sd = 15))

# Figure
g_lin <- 
  ggplot(data = data_lin, aes(x = x, y = y)) + 
  geom_point() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank()) +
  xlab("X") +
  ylab("Y") +
  ggtitle("Linéaire")

g_log <- 
  ggplot(data = data_log, aes(x = x, y = y)) + 
  geom_point() +
  scale_x_continuous(limits = c(-1, 15)) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank()) +
  xlab("X") +
  ylab("Y") +
  ggtitle("Logarithmique")

g_quad <- 
  ggplot(data = data_quad, aes(x = x, y = y)) + 
  geom_point() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank()) +
  xlab("X") +
  ylab("Y") +
  ggtitle("Quadratique")

(g_lin | g_log | g_quad)

```

Dans R, pour obtenir un nuage de points à partir d'un jeu de données, il est possible d'utiliser la fonction `ggplot()` en l'associant à la fonction `geom_point()` du package `ggplot2`, comme dans l'exemple ci-dessous qui utilise le jeu de données `mtcars` (qui est intégré à R de base) et les variables `hp` (*gross horsepower*) et `mpg` (*miles/US gallon*). Dans cet exemple, on peut voir que la relation semble gobalement linéaire négative (voire curvilinéaire négative si l'on donne de l'importance au point isolé à droite du graphique).

```{r scatterplot, fig.align = "center", fig.cap="Exemple de nuage de points"}
ggplot(data = mtcars, aes(x = hp, y = mpg)) + 
  geom_point()
```

### Etudier numériquement la relation

*Le coefficient de corrélation de Pearson* 

Lorsque la relation étudiée semble linéaire, l'étude numérique classique consiste à calculer le coefficient de corrélation de Pearson, noté $r$, dont la valeur vise à renseigner dans quelle mesure le nuage de points représentant le lien entre les deux variables étudiées suit une droite. Avant de se lancer dans le calcul du coefficient de corrélation de Pearson pour étudier la relation entre une variable $X$ et une variable $Y$, il peut donc être utile de compléter le nuage de points montré ci-dessus avec une droite d'équation de type $Y = aX + b$. Cette équation serait la meilleure modélisation possible de la relation linéaire entre $X$ et $Y$, de telle sorte que parmi l'infinité d'équations qui pourraient lier $X$ à $Y$, c'est cette équation qui au total donnerait la plus petite erreur lorsque l'on voudrait prédire $Y$ à partir de $X$. Si $X$ et $Y$ sont liées de manière linéaire, alors le nuage des points relatifs aux deux variables devrait s'étaler le long de cette droite. Pour obtenir cette droite en plus du nuage de points, il est possible d'utiliser la fonction `geom_smooth()` du package `ggplot2`.

```{r scatterplotLine, fig.align ="center", fig.cap="Nuage de points avec droite de régression"}
ggplot(data = mtcars, aes(x = hp, y = mpg)) + 
  geom_point() +
  geom_smooth(formula = y ~ x, method = "lm", se = FALSE)
```

Dans la fonction `geom_smooth()` qui a été utilisée dans l'exemple ci-dessus, on note que l'argument `formula` pourrait être considéré comme facultatif car il s'agit ici de la configuration par défaut de la fonction. En revanche, l'argument `method` doit être ici configuré avec `"lm"` (pour *linear model*) car ce n'est pas la méthode graphique configurée par défaut dans la fonction. Enfin, l'argument `se` permet de montrer ou non un intervalle de confiance autour de la droite de régression, ce qui n'a pas été activé ici (par défaut, l'argument `se` est configuré pour montrer cet intervalle de confiance). Dans l'exemple montré ci-dessus, la représentation graphique encourage fortement à penser que l'un des types de relations à envisager prioritairement dans l'étude des deux variables est la relation linéaire. Cette information rend pertinente l'utilisation du coefficient de corrélation de Pearson pour une étude numérique de la relation en question.

La valeur du coefficient de corrélation de Pearson peut aller de 1 (suggérant une relation linéaire positive parfaite) à -1 (suggérant une relation linéaire négative parfaite). Des valeurs proches de 0 suggèreraient une abscence de relation linéaire. La formule du coefficient de corrélation de Pearson ($r$) pour un échantillon est notée ci-dessous : 

$$r_{X,Y} =  {\frac{COV_{X,Y}}{s_{X} s_{Y}}} =  {\frac{\sum_{i=1}^{N} (X{i} - \overline{X}) (Y{i} - \overline{Y})}{N-1}} {\frac{1}{s_{X} s_{Y}}},$$

$COV$ désignant la covariance entre les variables $X$ et $Y$, $X{i}$ et $Y{i}$ les valeurs de $X$ et $Y$ pour une observation $i$, $\overline{X}$ et $\overline{Y}$ les moyennes des variables $X$ et $Y$, $N$ le nombre d'observations, et $s_{X}$ et $s_{Y}$ les écarts-types respectifs des variables $X$ et $Y$. Cette formule indique que le coefficient de corrélation de Pearson s'obtient en divisant la covariance des deux variables étudiées par le produit de leurs écarts-types respectifs. 

Le tableau ci-dessous montre les premières étapes du calcul de la covariance pour des couples de variables fictifs $(X1,Y1)$, $(X1,Y2)$, et $(X1,Y3)$. En particulier, la partie droite du tableau (de X1Y1 à X1Y3) montre le calcul du produit $(X{i} - \overline{X}) (Y{i} - \overline{Y})$ pour les différents couples de variables et cela pour chaque ligne du jeu de données.

```{r tablecov, echo = FALSE}
X1 <- c(0, 2, 4, 6, 8, 10, 12)
Y1 <- X1
Y2 <- c(0, 1, 15, 5, 11, 3, 12)
Y3 <- -X1

knitr::kable(
df <- 
  data.frame(X1 = X1, Y1 = Y1, Y2 = Y2, Y3 = Y3) %>%
  mutate(X1Y1 = (X1 - mean(X1)) * (Y1 - mean(Y1)),
         X1Y2 = (X1 - mean(X1)) * (Y2 - mean(Y2)),
         X1Y3 = (X1 - mean(X1)) * (Y3 - mean(Y3))),
caption = "Calcul de la covariance"
)
```

Ce que ce tableau peut permettre de rendre compte, c'est que plus les deux variables étudiées évolueront de manière consistante dans des sens identiques comme avec $X1$ et $Y1$, ou de manière consistante dans des sens opposés comme avec $X1$ et $Y3$, plus les produits $(X{i} - \overline{X}) (Y{i} - \overline{Y})$ donneront respectivement des grands scores positifs ou des grands scores négatifs, et moins les scores $(X{i} - \overline{X}) (Y{i} - \overline{Y})$ à additionner pour le calcul de la covariance s'annuleront. En effet, avec une relation relativement linéaire et positive les scores seront plus systématiquement positifs, et avec une relation relativement linéaire et négative les scores seront plus systématiquement négatifs. Toutefois, lorsqu'on aura des variables qui n'évolueront pas de manière consistante dans le même sens ou dans un sens opposé comme avec $X1$ et $Y2$, les scores positifs et négatifs liés aux calculs $(X{i} - \overline{X}) (Y{i} - \overline{Y})$ auront tendance à s'annuler et donneront lieu à une somme des scores $(X{i} - \overline{X}) (Y{i} - \overline{Y})$ diminuée, et donc à une covariance et au final à un coefficient de corrélation de Pearson tirés vers 0. Ces différents cas de figure et les calculs $(X{i} - \overline{X}) (Y{i} - \overline{Y})$ correspondants sont illustrés sur la figure ci-dessous. Sur cette figure, chaque carré correspond au calcul $(X{i} - \overline{X}) (Y{i} - \overline{Y})$, le carré étant bleu lorsque le résultat du calcul est positif, et rouge lorsque le résultat est négatif. L'aire d'un carré illustre la grandeur du score issu du calcul. Sur les figures de gauche et de droite, on distingue une relation linéaire parfaite, ce qui maximise les scores à additionner pour le calcul de la covariance, dans le positif pour la figure de gauche et dans le négatif pour la figure de droite. Au milieu, on remarque que le manque de relation linéaire donne lieu à des carrés à la fois bleus et rouges, indiquant que les scores associés aux calculs $(X{i} - \overline{X}) (Y{i} - \overline{Y})$ de la covariance s'annulent et diminuent ainsi la valeur finale de la covariance.

```{r graphCov, fig.align ="center", echo = FALSE, fig.width = 10, warning = FALSE, fig.cap="Détermination de la covariance"}
df <- 
  df %>%
  mutate(signX1Y1 = ifelse(X1Y1 > 0, "pos", "neg"),
         signX1Y2 = ifelse(X1Y2 > 0, "pos", "neg"),
         signX1Y3 = ifelse(X1Y3 > 0, "pos", "neg"))

COV1 <- sum(df$X1Y1) / (length(df$X1Y1) - 1)
COV2 <- sum(df$X1Y2) / (length(df$X1Y2) - 1)
COV3 <- sum(df$X1Y3) / (length(df$X1Y3) - 1)

library(grid)

g1 <- 
  ggplot(data = df) + 
  geom_rect(aes(xmin = X1, ymin = Y1, xmax = mean(X1), ymax = mean(Y1), fill = signX1Y1), alpha = 0.3) +
  geom_smooth(aes(X1, Y1), formula = y ~ x, method = "lm", se = FALSE, color = "black") +
  geom_point(aes(X1, Y1), color = "black", size = 3) + 
  geom_vline(aes(xintercept = mean(X1)), color = "black") + 
  geom_hline(aes(yintercept = mean(Y1)), color = "black") +
  scale_x_continuous(breaks = seq(0, 12, 2)) +
  scale_y_continuous(breaks = seq(0, 12, 2)) +
  scale_fill_manual(values = c("blue", "red"), breaks = c("pos", "neg"), labels = c("Tire la corrélation vers 1", "Tire la corrélation vers -1")) +
  xlab("X1") +
  ylab("Y1") +
  labs(fill = "", subtitle = bquote(paste("COV"["X1,Y1"]* " = ", .(round(COV1), digits = 1), "; SD"["X1"]*"SD"["Y1"]* " = ", .(round(sd(X1) * sd(Y1)), digits = 1)))) +
  ggtitle(bquote(paste("r"["X1,Y1"]* " = ", .(cor(X1, Y1), digits = 2)))) +
  geom_segment(aes(x = 2.8, y = 9.5, xend = 5.9, yend = 8.5), arrow = arrow(length = unit(0.5, "cm")), size = 0.8) +
  annotate("text", label = bquote(italic(bar(X)["1"])), x = 1.8, y = 9.7, size = 7) +
  geom_segment(aes(x = 9, y = 4, xend = 7, yend = 5.9), arrow = arrow(length = unit(0.5, "cm")), size = 0.8) +
  annotate("text", label = bquote(italic(bar(Y)["1"])), x = 9.9, y = 4, size = 7) +
  theme(axis.title = element_text(size = 15))


g2 <- 
  ggplot(data = df) +
  geom_rect(aes(xmin = X1, ymin = Y2, xmax = mean(X1), ymax = mean(Y2), fill = signX1Y2), alpha = 0.3) +
  geom_smooth(aes(X1, Y2), formula = y ~ x, method = "lm", se = FALSE, color = "black") +
  geom_point(aes(X1, Y2), color = "black", size = 3) + 
  geom_vline(aes(xintercept = mean(X1)), color = "black") + 
  geom_hline(aes(yintercept = mean(Y2)), color = "black") +
  scale_x_continuous(breaks = seq(0, 12, 2)) +
  scale_y_continuous(breaks = seq(0, 15, 3)) +
  scale_fill_manual(values = c("blue", "red"), breaks = c("pos", "neg"), labels =  c("Tire la corrélation vers 1", "Tire la corrélation vers -1")) +
  xlab("X1") +
  ylab("Y2") +
  labs(fill = "", subtitle = bquote(paste("COV"["X1,Y2"]* " = ", .(round(COV2), digits = 1), "; SD"["X1"]*"SD"["Y2"]* " = ", .(round(sd(X1) * sd(Y2)), digits = 1)))) +
  ggtitle(bquote(paste("r"["X1,Y2"]* " = ", .(round(cor(X1, Y2), digits = 1))))) +
  theme(axis.title = element_text(size = 15))


g3 <-
  ggplot(data = df) +
  geom_rect(aes(xmin = X1, ymin = Y3, xmax = mean(X1), ymax = mean(Y3), fill = signX1Y3), alpha = 0.3) +
  geom_smooth(aes(X1, Y3), formula = y ~ x, method = "lm", se = FALSE, color = "black") +
  geom_point(aes(X1, Y3), color = "black", size = 3) + 
  geom_vline(aes(xintercept = mean(X1)), color = "black") + 
  geom_hline(aes(yintercept = mean(Y3)), color = "black") +
  scale_x_continuous(breaks = seq(0, 12, 2)) +
  scale_y_continuous(breaks = seq(-15, 0, 3)) +
  scale_fill_manual(values = c("blue", "red"), breaks = c("pos", "neg"), labels =  c("Tire la corrélation vers 1", "Tire la corrélation vers -1")) +
  xlab("X1") +
  ylab("Y3") +
  labs(fill = "", subtitle = bquote(paste("COV"["X1,Y3"]* " = ", .(round(COV3), digits = 1), "; SD"["X1"]*"SD"["Y3"]* " = ", .(round(sd(X1) * sd(Y3)), digits = 1)))) +
  ggtitle(bquote(paste("r"["X1,Y3"]* " = ", .(round(cor(X1, Y3), digits = 1))))) +
  theme(axis.title = element_text(size = 15))

((g1 | g2) + plot_layout(guides = "collect") & theme(legend.position = "bottom", legend.text = element_text(size = 12)) | (g3 + theme(legend.position = "none")))
```

Dans R, le coefficient de corrélation de Pearson peut être obtenu avec la fonction `cor()`. Dans l'exemple ci-dessous qui reprend les variables du jeu de données `mtcars` utilisées plus haut, on observe un coefficient négatif, relativement proche de -1, suggérant une relation relativement linéaire et négative entre les variables étudiées.

```{r cor function}
cor(x = mtcars$hp, y = mtcars$mpg, method = "pearson")
```

Toutefois, la fonction `cor.test()` sera plus intéressante pour la suite car elle permet de calculer des indices statistiques de probabilité qui seront nécessaires dès lors qu'il s'agira de chercher à inférer la valeur d'une corrélation dans une population d'où l'échantillon étudié provient. La valeur de la corrélation est  donnée à la fin de la liste des informations qui apparaissent suite à l'activation de la fonction.

```{r cor.test function}
cor.test(x = mtcars$hp, y = mtcars$mpg, method = "pearson")
```

Sur la base de travaux antérieurs, Hopkins et al. [-@hopkinsProgressiveStatisticsStudies2009] ont fait une proposition de classification pour qualifier la valeur du coefficient de corrélation qui serait obtenue dans le cadre d'une relation linéaire. Cette proposition est montrée ci-dessous :

```{r correlationtable, echo = FALSE}
knitr::kable(
  tribble(
    ~Petite, ~Moyenne, ~Grande, ~"Très grande", ~"Extrêmement grande",
    0.1,     0.3,      0.5,     0.7,            0.9
  ),
  caption = "Taille d'effet pour une corrélation"
)
```

Pour visualiser le lien que l'on peut faire entre la forme du nuage de points et la valeur du coefficient de corrélation de Pearson que l'on peut obtenir, la page web proposée par Kristoffer Magnusson (https://rpsychologist.com/correlation) peut être particulièrement intéressante. Cette page web donne la possibilité de faire varier manuellement la valeur du coefficient de corrélation de Pearson pour ensuite voir un nuage de points type correspondant à cette valeur. Faites un essai !

A noter que la valeur du coefficient de corrélation de Pearson est très dépendante de la manière dont sont distribuées les variables, avec une influence particulière de la variabilité des données [@halperinSpuriousCorrelationsCauses1986]. L'influence de la variabilité est illustrée sur la figure ci-dessous. A gauche, on observe un nuage de points représentant une population complète, avec en conséquence une variablité le long des axes $X$ et $Y$ relativement importante. La valeur du coefficient de corrélation de Pearson est ici particulièrement élevée. A droite, on observe exactement les mêmes valeurs, mais sur un intervalle dont l'étendue a été manuellement restreinte, diminuant ainsi la variabilité. On observe alors une diminution de la valeur du coefficient de corrélation de Pearson, alors qu'il s'agit à l'origine du même jeu de données que celui de gauche. Cet exemple doit faire prendre conscience qu'il faut faire attention lorsqu'on cherche à comparer des coefficient de corrélation de Pearson obtenus avec différents échantillons présentant des caractéristiques différentes, car si ces échantillons n'ont pas les mêmes niveaux de variabilité, les valeurs des coefficients de corrélation ne seront pas vraiment comparables, en sachant que c'est l'échantillon qui présente la plus grande variabilité qui aura mathématiquement plus de chances de présenter une valeur de coefficient de corrélation plus élevée.

```{r spuriousCorrelations, echo = FALSE, warning=FALSE, message=FALSE,  fig.align ="center", fig.cap = "Coefficient de corrélation de Pearson et variabilité des données"}
g_lin <- 
  ggplot(data = data_lin, aes(x = x, y = y)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  scale_x_continuous(limits = c(-8, 10)) +
  scale_y_continuous(limits = c(-20, 25)) +
  xlab("X") +
  ylab("Y") +
  ggtitle(bquote(paste("r = ", .(round(cor(x = data_lin$x, y = data_lin$y), 2)))))

g_lin_sel <- 
  ggplot(data = filter(data_lin, x >-1 & x < 2.5), aes(x = x, y = y)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  scale_x_continuous(limits = c(-8, 10)) +
  scale_y_continuous(limits = c(-20, 25)) +
  xlab("X") +
  ylab("Y") +
  ggtitle(bquote(paste("r = ", .(round(cor(x = filter(data_lin, x >-1 & x < 2.5)$x, y = filter(data_lin, x >-1 & x < 2.5)$y), 2)))))

g_lin | g_lin_sel
```

Un exemple extrême de l'influence de la variabilité des données sur la valeur du coefficient de corrélation de Pearson est montré sur la figure ci-dessous. Les deux graphiques montrent exactement les mêmes données, à ceci près que sur le graphique de droite, on a remplacé en ordonnées une valeur du graphique de gauche pour lui donner la valeur de 10. L'influence de cette action sur la valeur du coefficient de corrélation est particulièrement nette, alors qu'une seule valeur a été modifée. Ceci montre qu'il faut faire attention aux valeurs extrêmes qui pourraient grandement influencer la valeur de corrélation obtenue, notamment en présence d'échantillons de taille relativement faible. Dans le cas où la valeur du coefficient de corrélation de Pearson serait très influencée par une valeur, il pourrait être une bonne pratique de calculer la valeur du coefficient de corrélation avec et sans cette valeur afin de pouvoir quantifier son influence sur la relation étudiée [@halperinSpuriousCorrelationsCauses1986]. Une alternative pourrait être aussi d'étudier la relation à l'aide d'autres types de coefficients que celui de Pearson, tels que celui de Spearman, présenté plus bas. Toutes ces informations doivent en tous les cas faire prendre conscience qu'il n'est pas toujours pertinent de calculer le coefficient de corrélation de Pearson. En ce sens, lorsqu'on cherche à inférer la valeur du coefficient de corrélation de Pearson dans la population étudiée, et cela avec un degré d'incertitude bien défini, il convient de vérifier certains prérequis, lesquels seront abordés plus tard dans ce livre. 

```{r spuriousCorrelationBis,  echo = FALSE, , fig.align ="center", message = FALSE, warning = FALSE, fig.cap="Coefficient de corrélation de Pearson et outliers"}
data1 <- tibble(x = c(0, 1, 2, 3, 4, 5), y = c(2, 4, 3, 2, 3, 4))
data2 <- tibble(x = c(0, 1, 2, 3, 4, 5), y = c(2, 4, 3, 2, 3, 10))


g1 <- 
  ggplot(data = data1, aes(x = x, y = y)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = FALSE) +
  scale_x_continuous(limits = c(-5, 10)) +
  scale_y_continuous(limits = c(-5, 15)) +
  xlab("X") +
  ylab("Y") +
  ggtitle(bquote(paste("r = ", .(round(cor(x = data1$x, y = data1$y), 2)))))

g2 <- 
  ggplot(data = data2, aes(x = x, y = y)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = FALSE) +
  scale_x_continuous(limits =c(-5, 10)) +
  scale_y_continuous(limits = c(-5, 15)) +
  xlab("X") +
  ylab("Y") +
  ggtitle(bquote(paste("r = ", .(round(cor(x = data2$x, y = data2$y), 2)))))

g1 | g2
  
```

Lorsque la relation étudiée ne semble pas linéaire mais s'apparente assez clairement à d'autres fonctions mathématiques, telles que des relations logarithmiques ou polynomiales, il est possible de transformer une des variables, voire les deux, pour rendre la relation linéaire et à nouveau étudiable à l'aide du coefficient de corrélation de Pearson [@halperinSpuriousCorrelationsCauses1986]. Toutefois, il est aussi possible de créer des modèles de régression non linéaires afin de regarder si ces modèles correspondent bien aux données. La détermination et la validation d'un modèle non linéaire qui correspondrait bien aux données confirmerait alors que la relation étudiée a une forme particulière et potentiellement prédictible. Les procédures pour explorer différents modèles de régression (linéaires et non linéaires) sont abordées au chapitre suivant. Enfin, une dernière alternative possible, pour étudier la relation entre deux variables quantitatives dont les distributions ne permettraient pas d'utiliser correctement le coefficient de corrélation de Pearson, serait l'utilisation de coefficients de corrélation basés sur les rangs, tels que le coefficient de corrélation de Spearman.

*Le coefficient de corrélation de Spearman*

Lorsque le coefficient de corrélation de Pearson ne permet pas de caractériser fiablement le degré de relation linéaire **entre les valeurs** de deux variables (par exemple en présence de valeurs aberrantes au sein d'un échantillon de petite taille), une alternative peut être d'étudier le degré de relation linéaire **entre les rangs** de ces deux variables. Le rang, c'est le classement (ou la position) d'une observation donnée en fonction de sa valeur. Dans une variable, les observations avec les valeurs les plus faibles seront associées aux rangs les plus bas alors que les observations avec les valeurs les plus élevées seront associées aux rangs les plus élevés. Une illustration de la notion de rang est proposée ci-dessous pour la variable `hp` du jeu de données `mtcars`. Dans le tableau ci-dessous, les lignes ont été ordonnées sur la base des rangs de la variable `hp`. On pourra remarquer que dans le tableau, nous avons ce qu'on appelle des ex-aequos, c'est-à-dire que plusieurs observations peuvent présenter les mêmes valeurs, et donc avoir le même rang.

```{r tableranks, echo = FALSE}
knitr::kable(
 mtcars %>%
   select(hp) %>%
   mutate(hp_rank = rank(hp)) %>%
   arrange(hp_rank),
 caption = "Les rangs d'une variable"
)
```

Le fait d'étudier l'existence d'une relation linéaire entre les rangs et non plus entre les valeurs de deux variables permet de s'affranchir de l'influence possible de valeurs très extrêmes, dans l'une et/ou l'autre variable, sur le calcul final de la corrélation. Pour déterminer alors la valeur de la corrélation, une manière de procéder est d'appliquer la méthode de calcul du coefficient de corrélation de Pearson en utilisant non plus les valeurs des variables, mais les rangs correspondants. Cette methode, c'est celle du calcul du coefficient de corrélation de Spearman (*rho*). Si l'on suit *stricto sensu* cette définition, nous pourrions alors utiliser le code suivant pour avoir le coefficient de corrélation de Spearman :

```{r cor function spearman}
cor(x = rank(mtcars$hp), y = rank(mtcars$mpg), method = "pearson")
```

Toutefois, il existe une manière plus directe d'écrire les choses avec la fonction `cor`, qui contient un argument spécifiquement dédié au calcul du *rho* de Spearman : 

```{r cor function spearman bis}
cor(x = mtcars$hp, y = mtcars$mpg, method = "spearman")
```

La fonction `cor.test` permet aussi de calculer le coefficient de corrélation de Spearman en fournissant d'autres informations potentiellement intéressantes pour donner une idée de la significativité statistique de l'estimation de *rho* pour la population étudiée.

```{r cor.test function spearman, warning=FALSE}
cor.test(x = mtcars$hp, y = mtcars$mpg, method = "spearman")
```

Si l'on veut produire une représentation graphique qui illustre la valeur de *rho* obtenue, il pourrait être davantage pertinent de non plus montrer un nuage de points à partir des valeurs des variables mises en lien, mais un nuage de points à partir de leurs rangs respectifs.

```{r graphSpearman, fig.align="center", message=FALSE, fig.cap="Graphique de corrélation pour le coefficient de Spearman"}
mtcars %>%
  mutate(hp_rank = rank(hp), mpg_rank = rank(mpg)) %>%
  ggplot(aes(x = hp_rank, y = mpg_rank)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

En matière d'interprétation, des valeurs de *rho* positives indiqueront que les deux variables mises en lien tendent à augmenter simultanément, on parlera alors de **relation monotone positive**. Dans le cas inverse, des valeurs négatives indiqueront que les deux variables mises en lien tendent à diminuer simultanément, on parlera alors de relation **monotone négative**. A noter cependant que de par son calcul, la valeur de *rho* ne permet pas de renseigner sur la forme de relation qu'il pourrait y avoir entre les valeurs des deux variables (e.g., linéaire ou curvilinéaire par exemple). Ceci est illustré sur la figure ci-dessous. La figure de gauche montre la relation entre les valeurs des variables $X$ et $Y$, qui est caractérisée par un coefficient de corrélation de Spearman (*rho*) de 1, indiquant donc que la relation est parfaitement monotone positive, sans préjuger de la forme particulière que pourrait présenter la relation. Pour mieux comprendre pourquoi cette valeur de *rho* est de 1, la figure de droite montre la relation entre les rangs de ces deux variables $X$ et $Y$. On voit en effet que la relation entre les rangs est effectivement parfaitement linéaire.

```{r ranksvvaluesspearman, echo = FALSE, fig.align = "center", fig.cap="Explication du caractère monotone d'une variable évalué par le coefficient de Spearman"}
a <- 
  data.frame(x = seq(1, 50, 1)) %>%
  mutate(y = log(x)) %>%
  ggplot(aes(x = x, y = y)) +
  xlab("X") +
  ylab("Y") +
  geom_point() +
  ggtitle("Y vs. X")

b <- 
  data.frame(x = seq(1, 50, 1)) %>%
  mutate(y = log(x), rang_X = rank(x), rang_Y = rank(y)) %>%
  ggplot(aes(x = rang_X, y = rang_Y)) + 
  geom_point() +
  xlab("Rang X") +
  ylab("Rang Y") +
  ggtitle("Rang Y vs. Rang X")

a | b
```


## Relation entre deux variables qualitatives
### Etudier graphiquement la relation
Plusieurs types de graphiques peuvent être envisagés lorsqu'il s'agit de montrer les données relatives au croisement de deux variables qualitatives. Une première approche consiste à utiliser des graphiques avec barres mises côte-à-côte et groupées sur l'axe horizontal en fonction des modalités d'une première variable, et colorées en fonction de la seconde variable. Cela est illustré sur la figure ci-dessous, qui a été réalisée à partir du jeu de données `JointSports`, lequel est utilisable après installation et chargement du package `vcd`. `JointSports` contient des données résumées avec des effectifs mis en lien avec les modalités de différentes variables qualitatives, comme on a pu l'obtenir avec les fonctions `group_by` et `summarize` dans les derniers exemples du chapitre précédent. (La différence qu'il y a ici avec ces précédents exemples est qu'ici, l'effectif est désigné par la variable `Freq`, alors qu'il s'agissait de la variable `count` auparavant.) Pour information, `JointSports` contient les données d'une enquête s'étant intéressée, en 1983 et 1985, aux opinions d'étudiants danois de 16 à 19 ans quant à la pratique sportive mixte. On note également que le code montré ci-dessous, qui a servi à générer les graphiques à suivre, utilise la fonction `theme_hc()` du package `ggthemes` afin de pouvoir utiliser des couleurs de remplissage automatique particulières. Le package `ggthemes` doit être installé puis chargé pour pouvoir être utilisé.

```{r loading vdc and ggthemes, warning=FALSE}
library(vcd)
library(ggthemes)
```

```{r grouped bars code, message = FALSE, warning = FALSE}
# Reconfiguration de l'ordre des modalités de la variable opinion, et calcul des effectifs totaux pour les catégories étudiées
JointSports_new <- 
  JointSports %>%
  mutate(opinion = fct_relevel(opinion, "very bad", "bad", "indifferent", "good", "very good"),
         gender = fct_relevel(gender, "Girl", "Boy")) %>%
  group_by(gender, opinion) %>%
  summarize(Freq = sum(Freq))

# Création des graphiques
g1 <- 
  ggplot(data = JointSports_new, aes(x = gender, y = Freq, fill = opinion)) +
  geom_bar(stat = "identity",  position = "dodge") +
  scale_fill_brewer(palette = "Greens") +
  theme_hc() +
  theme(legend.position = "right") +
  ggtitle("g1 : Mise en avant de la comparaison des opinions")

g2 <- 
  ggplot(data = JointSports_new, aes(x = opinion, y = Freq, fill = gender)) +
  geom_bar(stat = "identity",  position = "dodge") +
  theme_hc() +
  theme(legend.position = "right") +  
  ggtitle("g2 : Mise en avant de la comparaison des genres")
```


```{r groupedBarsFigure, echo = FALSE, fig.align="center", fig.cap="Exemples de diagramme en barres mises côte-à-côte"}
g1 / g2
```

Pour pouvoir réaliser le graphique g1 montré ci-dessus, il a fallu indiquer dans la fonction `ggplot()`, grâce à `x = `, la variable dont on voulait voir les modalités en abscisses, et il a fallu renseigner pour les ordonnées, à l'aide de `y = `, la variable contenant les effectifs correspondants, le tout toujours à l'intérieur de l'argument `aes()`. Etant donné que les données à montrer le long de l'axe des ordonnées sont explicitement indiquées avec `Freq`, il convient d'indiquer à l'intérieur de la fonction `geom_bar()` l'argument `stat = "identity"`, ce qui contraint à determiner la hauteur des barres en fonction des valeurs de la variable `Freq`. A l'intérieur de la fonction `ggplot()` et de l'argument `aes()`, c'est l'argument `fill = opinion` qui a permis d'indiquer qu'on voulait des couleurs de remplissage différentes selon les modalités de la variable `opinion`. Enfin, c'est grâce à l'argument `position = "dodge"`, à l'intérieur de la fonction `geom_bar()`, que l'on a pu obtenir des barres mises côte-à-côte, et non pas de manière empilée. Une logique similaire a été utilisée pour le graphique g2 en modifiant le code de telle sorte que la distinction de l'information avec des couleurs différentes se fasse avec la variable `gender`, et non plus `opinion`.

Les graphiques g1 et g2 montrent l'importance de la configuration du graphique en fonction des comparaisons que l'on veut principalement faire, et donc du message que l'on veut prioritairement délivrer. Un principe qui peut guider la conception du graphique est le fait qu'il est plus facile de comparer des barres qui sont mises juste côte-à-côte. Sur la base de ce principe, le graphique g1 ci-dessus permet de comparer plus facilement les diverses opinions relevées pour les garçons d'un côté et pour les filles de l'autre, alors que le graphique g2 permet de comparer plus facilement les réponses provenant des deux genres et cela pour chaque type d'opinion. Comme indiqué par Wilke [-@wilkeFundamentalsDataVisualization2018], les types de graphiques illustrés avec les graphiques g1 et g2 ci-dessus peuvent parfois se voir attribuer le reproche que s'il est relativement facile de lire les informations encodées par des positions (cf. ligne de base sur les graphiques), il peut être être difficile de lire les informations encodées par une couleur dont la signification est indiquée en légende, car cela demande un effort mental supplémentaire de garder en tête la signification de la légende lorsqu'on lit le graphique. Pour palier ce problème, qui, selon Wilke [-@wilkeFundamentalsDataVisualization2018], est au final une affaire de goût, on pourrait utiliser la fonction `facet_wrap()` pour créer une figure telle qu'illustré ci-dessous. (La figure ci-dessous reprend la logique du graphique g1 montré plus haut, avec un besoin de légende pour la variable `opinion` qui n'existe plus car la fonction `facet_wrap()` a permis de montrer les diagrammes en barres pour les deux genres de manière séparée, dans des encarts différents, et avec chacun leur propre axe des abscisses relatif aux modalités de la variable `opinion`.)

```{r groupedBarsUpgraded, fig.align="center", message = FALSE, fig.cap="Diagrammes en barres côte-à-côte séparés selon une variable catégorielle"}
ggplot(data = JointSports_new, aes(x = opinion, y = Freq)) +
  geom_bar(stat = "identity") +
  facet_wrap(. ~ gender)
```

Dans certains cas, on peut vouloir comparer les effectifs relatifs aux modalités d'une première variable qualitative avec des barres mises côte-à-côte, et n'utiliser la seconde variable qualitative que pour avoir un peu d'éléments de contexte "à l'intérieur" des effectifs affichés pour la première variable qualitative. La figure ci-dessous illustre ce cas de figure où la hauteur des barres sert prioritairement à comparer les effectifs relatifs à diverses opinions, et la coloration des barres sert à fournir une idée de la répartition hommes / femmes dans les réponses, sans pourtant avoir l'ambition de comparer cette répartition hommes / femmes  facilement d'un type d'opinion à un autre.

```{r stackedBarsBiv, fig.align="center", message = FALSE, fig.cap= "Exemple de diagramme en barres empilées"}
JointSports_new %>%
  ggplot(aes(x = opinion, y = Freq, fill = gender)) +
  geom_bar(stat = "identity") +
  theme_hc() +
  geom_text(aes(label = Freq), size = 3, position = position_stack(vjust = 0.5))
```

Les graphiques présentés dans cette sous-partie montrent des valeurs d'effectifs, mais selon l'objectif, il pourrait être aussi envisagé d'utiliser ces graphiques pour montrer des proportions. Cela dit, il existe d'autres visualisations possibles des proportions pour visualiser le lien entre deux variables qualitatives. Ces visualisations peuvent être consultées dans l'ouvrage en ligne de Wilke [-@wilkeFundamentalsDataVisualization2018].


### Etudier numériquement la relation

*Effectifs et proportions*

Lorsqu'il s'agit de mener une étude numérique de la relation entre deux variables qualitatives, une première démarche à mettre en oeuvre est de récapituler numériquement les effectifs qui correspondent au croisement des deux variables. Pour cela, la fonction `table()` intégrée à R de base s'avère très pratique. Cependant, cette fonction requiert d'utiliser le jeu de données initial complet (i.e., avec toutes les observations), ce qui n'est pas le cas du jeu de données `JointSports` que nous avons utilisé juste précédemment, car ce dernier contient des effectifs déjà récapitulés par modalité de variable. Pour pouvoir illustrer le fonctionnement de la fonction `table()` avec les informations du jeu de données `JointSports`, j'ai donc crée un jeu de données complet qui, une fois résumé comme c'est le cas plus haut avec `JointSports`, donnerait les mêmes résultats. Ce nouveau jeu de données se nomme `JointSports_full`.

```{r JointSports_full}

id <- rep(1 : sum(JointSports$Freq))
year <- c(rep("1983", 656), rep("1985", 615))
grade <- c(rep("1st", 350), rep("3rd", 306), rep("1st", 354), rep("3rd", 261))
gender <- c(rep("Boy", 134), rep("Girl", 216), rep("Boy", 115), rep("Girl", 191), rep("Boy", 157), rep("Girl", 197), rep("Boy", 104), rep("Girl", 157))
opinion <- c(
  rep("very good", 31), rep("good", 51), rep("indifferent", 38), rep("bad", 10), rep("very bad", 4), 
  rep("very good", 103), rep("good", 67), rep("indifferent", 29), rep("bad", 15), rep("very bad", 2), 
  rep("very good", 23), rep("good", 39), rep("indifferent", 36), rep("bad", 15), rep("very bad", 2), 
  rep("very good", 61), rep("good", 72), rep("indifferent", 39), rep("bad", 16), rep("very bad", 3), 
  rep("very good", 41), rep("good", 67), rep("indifferent", 35), rep("bad", 12), rep("very bad", 2), 
  rep("very good", 77), rep("good", 80), rep("indifferent", 27), rep("bad", 10), rep("very bad", 3), 
  rep("very good", 31), rep("good", 31), rep("indifferent", 31), rep("bad", 4), rep("very bad", 7), 
  rep("very good", 52), rep("good", 70), rep("indifferent", 28), rep("bad", 4), rep("very bad", 3)
  )

JointSports_full <- 
  data.frame(id = id, year = year, grade = grade, gender = gender, opinion = opinion) %>%
  mutate(opinion = fct_relevel(opinion, "very bad", "bad", "indifferent", "good", "very good"))
```

Une fois que l'on a un jeu de données complet sous la main, il est possible de créer ce qu'on appelle un **tableau de contingence**, c'est-à-dire ici un tableau qui récapitule numériquement les effectifs à la croisée des deux variables qui nous intéressent. Pour faire cela, on peut utiliser la fonction `table()` en suivant différentes méthodes montrées ci-dessous. (Le code montré ci-dessous aboutit aux mêmes informations que celles montrées sur le denier graphique ci-dessus.)

```{r contingence table}
# 1ère méthode
tab <- 
  with(JointSports_full,
       table(opinion, gender))

# 2ème méthode
tab <- table(JointSports_full$opinion, JointSports_full$gender)

# Visualisation du tableau de contingence
tab
```

Un tableau de contingence permet donc de comparer des effectifs en fonction de plusieurs modalités et variables à la fois. Le problème, lorsqu'on utilise des effectifs, est que certaines comparaisons peuvent être difficiles à faire lorsque les effectifs totaux liés aux différentes modalités ne sont pas comparables. Par exemple, dans le tableau montré ci-dessus, l'effectif total des filles est de 761 alors que celui des garçons est de 510, ce qui rend difficile la comparaison des garçons et des filles pour les différents types d'opinion recensés dans l'enquête danoise présentée plus haut. C'est pour cela qu'il convient, dans certains cas, de calculer les proportions correspondant à ces différents effectifs. Pour ce faire, on peut :

- Utiliser la fonction `prop.table()`, qui va convertir en proportions les effectifs montrés plus haut en considérant l'effectif total de tout le tableau :

```{r prop.table}
round(prop.table(tab) * 100, digits = 2)
```


```{r loading questionr, message=FALSE, warning=FALSE, echo=FALSE}
library(questionr)
```

- Utiliser la fonction `lprop()` du package `questionr`, qui va convertir en proportions les effectifs montrés plus haut en considérant l'effectif total de chaque ligne du tableau :

```{r lprop tab, message=FALSE, warning=FALSE, echo=FALSE}
lprop(tab)
```

- Utiliser la fonction `cprop()` du package `questionr`, qui va convertir en proportions les effectifs montrés plus haut en considérant l'effectif total de chaque colonne du tableau :

```{r cprop tab}
cprop(tab)
```

Il convient bien de noter que les proportions données par ces différentes fonctions doivent être utilisées selon les comparaisons que l'on veut faire. L'analyse descriptive consiste alors à voir si, tant d'un point de vue graphique que numérique, on observe des différences de scores particulières entre les modalités d'une variable qualitative en fonction des modalités de l'autre variable qualitative. Si l'on considère le dernier tableau, on peut par exemple observer une très légère tendance à ce que les garçons soient davantage polarisés, par rapport aux filles, sur des opinions négatives vis-à-vis des pratiques sportives mixtes, alors que les filles seraient légèrement plus polarisées que les garçons sur des opinions positives, ce qui n'empêche pas que, pour les deux genres, il y a une polarisation principale sur des opinions neutres à positives.

Si l'on a évoqué l'idée que les proportions permettent de mieux comparer les choses, il convient de faire attention malgré tout à la manière dont l'effectif total associé à une modalité d'une variable se répartit selon les modalités de la seconde variable, car une répartition non homogène de l'effectif lié à une modalité d'une variable dans les différentes modalités de la seconde variable peut donner lieu à des conclusions tout à fait différentes selon que l'on considère une analyse globale ou une analyse par modalité. Un exemple connu pour illustrer le type de situations dans lesquelles il faut être vigilant est le cas du taux de réussite des femmes à l'université de Berkeley en 1973 qui était bien inférieur à celui des hommes lorsqu'on considérait les taux de réussite à l'échelle de l'ensemble de l'unversité [@bickelSexBiasGraduate1975]. Toutefois, une analyse par matière permettait de voir que les taux de réussite des femmes étaient très similaires à ceux des hommes dans la plupart des matières, voire étaient largement supérieurs à celui des hommes dans certaines matières. Cette situation, qui paraît de prime abord paradoxale, illustre pleinement ce qu'on appelle un paradoxe de Simpson (i.e., le fait que le résultat observé lors d'une analyse globale d'un groupe  puisse se retrouver annulée voire inversée lors d'une analyse à l'échelle de sous-groupes). Dans le cas présent, le paradoxe s'explique par le fait que la majorité des femmes avaient candidaté dans des matières qui étaient très sélectives, c'est-à-dire où le taux de réussite était faible (il l'était aussi pour les hommes). Très peu de femmes avaient candidaté là où les taux de réussite étaient très élevés (pour les femmes comme pour les hommes). Donc au total, les hommes se retrouvaient avec un pourcentage de réussite global bien meilleur que celui des femmes, seulement parce que en proportions, plus d'hommes s'étaient engagés dans les matières où les taux de réussite étaient bien meilleurs.


## Relation entre une variable quantitative et une variable qualitative
Lorsqu'on analyse une variable quantitative en fonction d'une variable qualitative, on peut notamment distinguer le fait que les données quantitatives soient pairées (*within-subject design* en anglais) ou non (*between-subject design* en anglais). Avoir des données non pairées signifie que pour chaque modalité de la variable qualitative étudiée, les données quantitatives correspondantes ne sont pas liées. Un exemple simple peut être l'analyse de la taille des individus en fonction du sexe. Dans ce cas, les données quantitatives de taille pour le sexe masculin et pour le sexe féminin proviendront forcément d'individus différents et ne formeront donc pas des paires. En revanche, on peut aussi avoir des études dans lesquelles plusieurs individus sont évalués dans plusieurs conditions différentes que l'on chercherait à comparer. En sciences du sport, un exemple relativement classique est de tester la performance d'endurance (variable quantitative) en ayant pris (condition de test) ou non (condition contrôle) une substance potentiellement ergonénique (la prise de substance ou non étant les modalités d'une même variable qualitative de type condition). Dans ce cas là, tous les individus auront des données dans les deux conditions et ces données seront donc pairées (dépendantes).

### Etudier graphiquement la relation
Lorsque l'on cherche à explorer la relation qu'il peut y avoir entre une variable quantitative et une variable qualitative, il peut être intéressant de visualiser la distribution de la variable quantitative en fonction de chaque modalité de la variable qualitative. Plusieurs possibilités existent afin de faire cela. On peut tout d'abord vouloir visualiser les choses de long de l'axe vertical avec :

- des moyennes et écarts-types (cf. codes et graphiques ci-dessous) ;

```{r graph distri biv quand vs qual means, message = FALSE, warning = FALSE}
# Moyennes et barres d'erreur
g1 <- 
  ggplot(data = iris, aes(x = Species, y = Sepal.Length)) +
  stat_summary(fun.data = "mean_sdl", fun.args = list(mult=1), geom = "errorbar", na.rm = TRUE, size = 1, width = 0.2, color = "red") +
  stat_summary(fun = "mean", geom = "point", na.rm = TRUE, size = 5, color = "red") +
  ggtitle("g1") +
  theme(plot.title = element_text(size = 20),
        axis.title = element_text(size = 17),
        axis.text = element_text(size = 17))

# Moyennes, barres d'erreur, et points (l'installation du package Hmisc est nécessaire pour pouvoir utiliser "mean_sdl" ici)
g2 <- 
  ggplot(data = iris, aes(x = Species, y = Sepal.Length)) +
  geom_point(size = 3) +
  stat_summary(fun.data = "mean_sdl", fun.args = list(mult=1), geom = "errorbar", na.rm = TRUE, size = 1, width = 0.2, color = "red") +
  stat_summary(fun = "mean", geom = "point", na.rm = TRUE, size = 5, color = "red") +
  ggtitle("g2") +
  theme(plot.title = element_text(size = 20),
        axis.title = element_text(size = 17),
        axis.text = element_text(size = 17))

# Moyennes, barres d'erreur, et points avec mouvement latéral aléatoire (l'installation du package Hmisc est nécessaire pour pouvoir utiliser "mean_sdl" ici)
g3 <- 
  ggplot(data = iris, aes(x = Species, y = Sepal.Length)) +
  geom_jitter(width = 0.08, height = NULL, size = 3) +
  stat_summary(fun.data = "mean_sdl", fun.args = list(mult=1), geom = "errorbar", na.rm = TRUE, size = 1, width = 0.2, color = "red") +
  stat_summary(fun = "mean", geom = "point", na.rm = TRUE, size = 5, color = "red") +
  ggtitle("g3") +
  theme(plot.title = element_text(size = 20),
        axis.title = element_text(size = 17),
        axis.text = element_text(size = 17))
```

```{r graphDistriBivQuantvsQualMeans, fig.align="center", echo = FALSE, fig.width=20, fig.cap="Nuage de points avec moyennes et écart-types"}
library(patchwork)
g1 | g2 | g3
```

- des médianes et intervalles interquartiles (cf. codes et graphiques ci-dessous) ;

```{r graph distri biv quand vs qual med, message = FALSE, warning = FALSE}
# Boîtes à moustaches
g4 <- 
  ggplot(data = iris, aes(x = Species, y = Sepal.Length)) +
  geom_boxplot() +
  ggtitle("g4") +
  theme(plot.title = element_text(size = 20),
        axis.title = element_text(size = 17),
        axis.text = element_text(size = 17))

# Boîtes à moustaches et points
g5 <-
  ggplot(data = iris, aes(x = Species, y = Sepal.Length)) +
  geom_boxplot() +
  geom_point(size = 3) +
  ggtitle("g5") +
  theme(plot.title = element_text(size = 20),
        axis.title = element_text(size = 17),
        axis.text = element_text(size = 17))

# Boîtes à moustaches et points avec mouvement latéral aléatoire
g6 <- 
  ggplot(data = iris, aes(x = Species, y = Sepal.Length)) +
  geom_boxplot() +
  geom_jitter(width = 0.08, height = NULL, size = 3) +
  ggtitle("g6") +
  theme(plot.title = element_text(size = 20),
        axis.title = element_text(size = 17),
        axis.text = element_text(size = 17))
```

```{r graphDistriBivQuantvsQualMed, fig.align="center", echo = FALSE, fig.width=20, fig.cap="Nuage de points avec boîtes à moustaches"}
library(patchwork)
g4 | g5 | g6
```

- des aires de densité (cf. codes et graphiques ci-dessous).

```{r graph distri biv quand vs qual dens, message = FALSE, warning = FALSE}
# Aires de densité
g7 <- 
  ggplot(data = iris, aes(x = Species, y = Sepal.Length)) +
  geom_violin() +
  ggtitle("g7") +
  theme(plot.title = element_text(size = 20),
        axis.title = element_text(size = 17),
        axis.text = element_text(size = 17))

# Aires de densité et points
g8 <-
  ggplot(data = iris, aes(x = Species, y = Sepal.Length)) +
  geom_violin() +
  geom_point(size = 3) +
  ggtitle("g8") +
  theme(plot.title = element_text(size = 20),
        axis.title = element_text(size = 17),
        axis.text = element_text(size = 17))

# Aires de densité et points avec mouvement latéral aléatoire
g9 <- 
  ggplot(data = iris, aes(x = Species, y = Sepal.Length)) +
  geom_violin() +
  geom_jitter(width = 0.08, height = NULL, size = 3) +
  ggtitle("g9") +
  theme(plot.title = element_text(size = 20),
        axis.title = element_text(size = 17),
        axis.text = element_text(size = 17))
```

```{r graphDistriBivQuantvsQualdens, fig.align="center",  echo = FALSE, fig.width=20,  fig.cap = "Nuages de points avec aires de densité"}
g7 | g8 | g9
```

Les différentes lignes de graphiques ci-avant montrent des graphiques de plus en plus efficaces à mesure que l'on se déplace de la gauche vers la droite. Une bonne pratique est en effet de donner la possibilité de visualiser les données individuelles en plus des statistiques que l'on souhaiterait montrer pour résumer la distribution. Il s'agit d'une bonne pratique car une même statistique peut en réalité cacher des distributions de valeurs très différentes. Ce principe a été illustré notamment par Weissgerber [-@weissgerberBarLineGraphs2015] qui milite pour la disparition des graphiques en forme de bâtons de dynamite, lesquels sont souvent utilisés pour montrer des moyennes et écart-types. La raison est que ces graphiques en forme de bâtons de dynamite peuvent induire en erreur quant à la réelle forme de la distribution et ils limitent les possibilités du lecteur de juger de la pertinence des choix d'analyse qui seraient faits par la suite au regard des données d'origine.

On remarque que pour pouvoir montrer les moyennes et écart-types en rouge sur les premiers graphiques, il a fallu utiliser la fonction `stat_summary()`. Cette fonction permet de mettre en graphique certaines statistiques en configurant l'argument `fun` ou `fun.data`. Pour pouvoir enrichir les possibilités de mise en graphique de diverses statistiques, il peut falloir installer au préalable le package `Hmisc`, ce qui était nécessaire ici pour montrer les écart-types avec `fun.data = "mean_sdl"`.

Bien que l'on ait l'habitude d'utiliser des graphiques montrant les données de la variable quantitative sur l'axe vertical, il est possible de montrer les données sous formes d'aires de densité le long de l'axe horizontal (cf. graphique g13 ci-dessous) ou encore avec un graphique en lignes de crêtes (*ridgelines plot*, cf. graphique g14 ci-dessous). Ces types de graphiques et leurs intérêts ont été discutés par Wilke [-@wilkeFundamentalsDataVisualization2018]. Pour pouvoir faire le graphque g14, il faut installer et charger un nouveau package : `ggridges`.

```{r fig recap biv hori, message = FALSE, warning = FALSE}
# Aire de densités superposées
g13 <- 
  ggplot(data = iris, aes(x = Sepal.Length, fill = Species, color = Species)) +
  geom_density(alpha = 0.3, size = 2) +
  ggtitle("g13") +
  theme(plot.title = element_text(size = 20),
        axis.title = element_text(size = 17),
        axis.text = element_text(size = 17),
        legend.position = "bottom",
        legend.title = element_text(size = 20, face = "bold"),
        legend.text = element_text(size = 20))

# Ridgelines plot
library(ggridges)

g14 <-
  ggplot(data = iris, aes(x = Sepal.Length, y = Species)) +
  geom_density_ridges(size = 2) +
  ggtitle("g14") +
  theme(plot.title = element_text(size = 20),
        axis.title = element_text(size = 17),
        axis.text = element_text(size = 17))
```

```{r figrecapbivdens, fig.align="center", echo = FALSE, message = FALSE, warning = FALSE, fig.width = 20, fig.cap="Diagrammes en lignes de crête"}
g13 | g14
```

Lorsque les données à visualiser sont pairées, c'est-à-dire qu'il s'agit des mêmes individus qui ont des données pour chaque modalité de la variable qualitative (e.g., suite à une même mesure qui aurait été réalisée dans différentes conditions), il est possible d'ajouter des éléments graphiques, telles que des lignes, de telle sorte à mettre davantage en évidence le fait que les données soient liées. Un exemple de graphique pour cela est montré ci-dessous avec le jeu de données `mice2` (intégré au package `datarium`). Ce jeu de données contient des données de poids de 10 souris évaluées avant et après un traitement.

```{r loading datarium, echo = FALSE, warning = FALSE}
library(datarium)
head(mice2)
```

```{r pairedData, fig.align="center", fig.cap="Deux groupes avec données appariées"}
mice2 %>%
  pivot_longer(cols = c(before, after), names_to = "treatment", values_to = "score") %>%
  mutate(treatment = fct_relevel(treatment, "before", "after")) %>%
  ggplot(aes(x = treatment, y = score)) +
  geom_line(aes(group = id)) +
  geom_point(size = 3, shape = 21, fill  = "white") +
  stat_summary(aes(group = 1), fun = "mean",  geom = "line", color = "red", size = 1.3) +
  stat_summary(fun.data = "mean_sdl", fun.args = list(mult=1), geom = "errorbar", na.rm = TRUE, size = 1, width = 0.1, color = "red") +
  stat_summary(fun = "mean", geom = "point", na.rm = TRUE, size = 4, color = "red") 
```

Dans le code ayant permis de réaliser ce graphique, il faut comprendre qu'il a été possible de réaliser des lignes reliant les différents points blancs grâce à la fonction `geom_line()` associée à un argument permettant de tracer les lignes en groupant les informations par individu avec la variable `id` (`aes(group = id)`). L'ajout d'une ligne rouge reliant chaque moyenne a été permis par l'écriture d'une ligne de code similaire à celle utilisée pour montrer les moyennes en rouge pour chaque condition avec `stat_summary()`, si ce n'est qu'on a indiqué de vouloir voir une ligne au lieu de points. La configuration de l'argument `aes(group = 1)` à l'intérieur de la fonction `stat_summary()` était nécessaire pour pouvoir montrer la ligne rouge reliant les moyennes.

### Etudier numériquement la relation

De manière générale, étudier la relation entre une variable quantitative et une variable qualitative revient souvent à comparer les valeurs que prend la variable quantitative en fonction des modalités de la variable qualitative. Les analyses qui peuvent être faites dépendent du nombre de groupes de valeurs (qui dépendent du nombre de modalités) à comparer (2 ou plus), et du caractère pairé (dépendant) ou non des données. L'observation de différences de scores entre les modalités pourrait alors indiquer qu'il y a un lien entre la variable qualitative (qu'on pourrait appeler variable **facteur**) et la variable quantitative (qu'on pourrait appeler **variable réponse**). (A noter que la démonstration d'un lien de cause à effet entre la variable quantitative et la variable qualitative ne pourra être effective que si l'on a sciemment fait varier les modalités de la variable qualitative pour en observer la conséquence sur les valeurs de la variable quantitative.)

*Cas de deux groupes de données indépendants (données non pairées)*

De prime abord, l'analyse qui pourrait être envisagée pour comparer deux groupes de données quantitatives (e.g., des valeurs de taille) non pairées, qui seraient donc relatives à deux modalités différentes d'une variable qualitative (e.g., le sexe), serait de comparer les moyennes, ou les médianes des groupes. Toutefois, en se restreignant à cela, il pourrait être difficile de porter un jugement sur la grandeur relative de la différence qui serait observée, qu'on pourrait appeler **taille d'effet**. Il serait également difficile de comparer cette taille d'effet avec celles observées dans d'autres études, car étant calculée de la sorte, elle serait extrêmement inhérente aux variables et valeurs mesurées dans l'étude. Il est donc intéressant, dans ce genre de situation, de standardiser la différence des moyennes ou médianes obtenues pour les deux groupes. Cette procédure de standardisation a été très développée dans le cadre de comparaisons de moyennes, et les calculs suivants, repris de l'article de D. Lakens [-@lakensCalculatingReportingEffect2013], s'inscrivent donc dans ce cadre.

**ds de Cohen**

Classiquement, l'indice statistique utilisé pour calculer une différence de moyennes de manière standardisée entre deux groupes de données non pairées, à partir d'échantillons de population, est le $d_{s}$ de Cohen. Cette statistique se calcule en faisant la différence entre les moyennes des deux groupes à comparer, et en divisant cette différence par l'écart-type commun des valeurs de chacun des deux groupes. Ce calcul est montré ci-dessous : 

$$d_{s} = \frac{\overline{X_{1}} - \overline{X_{2}}} {\sqrt{\frac{(N_{1} - 1) s_{1}^2 + (N_{2} - 1) s_{2}^2} {N_{1} + N_{2} - 2}}}$$

Dans R, le $d_{s}$ de Cohen peut être calculé à l'aide de la fonction `cohens_d()` du package `effectsize`, qui nécessite d'être installé puis chargé avant d'être utilisé. Pour illustrer l'utilisation de cette fonction, on peut utiliser le jeu de données `iris_two_species` crée par nos soins à partir du jeu de données `iris` pour l'exemple, qui contient notamment la variable quantitative `Sepal.Length`, et deux modalités de la  variable qualitative `Species` (`setosa` et `versicolor`).

```{r iris2peciesview, echo = FALSE, warning = FALSE, fig.align="center", fig.cap="Deux groupes avec données non appariées"}
iris_two_species <-
  iris %>% 
  filter(Species == "setosa" | Species == "versicolor")
  
ggplot(data = iris_two_species, aes(x = Species, y = Sepal.Length)) +
  geom_jitter(size = 3, width = 0.08) +
  stat_summary(fun = "mean", color = "red", size = 1.1) +
  stat_summary(fun.data = "mean_sdl", fun.args = list(mult=1), geom = "errorbar", na.rm = TRUE, size = 1.8, width = 0.1, color = "red")
```

On peut alors calculer le $d_{s}$ de Cohen à l'aide de la fonction `cohens_d()` de la manière suivante : 

```{r effectsize loading, echo = FALSE, warning=FALSE, message=FALSE}
library(effectsize)
```

```{r cohens d between, warning=FALSE, message=FALSE}
cohens_d(Sepal.Length ~ Species, data = iris_two_species, paired = FALSE, pooled_sd = TRUE)
```

Dans cet exemple, on remarque qu'on a bien cherché à savoir comment les données de la variable `Sepal.Length` pouvaient différer en fonction (`~`) des modalités de la variable `Species`. Si la fonction nous donne un résultat, il faut toutefois bien faire attention au sens du calcul qui a été réalisé. Configurée de la sorte, la fonction `cohens_d()` réalise la différence **modalité 1 - modalité 2**. Il faut donc savoir quelle est la modalité 1 et quelle est la modalité 2 dans la variable `Species` pour ensuite pouvoir interpréter le signe du résultat, qui est négatif ici avec la valeur de -2.10. Pour ce faire, on peut utiliser la fonction `levels()` :

```{r levels function}
levels(iris_two_species$Species)
```

L'ordre des modalités affichées nous indique que `setosa` est la modalité 1, et que `versicolor` est la modalité 2. (On remarque par ailleurs que l'utilisation précédente de la fonction `filter()` a certes permis de sélectionner les données d'intérêt pour notre nouveau jeu de données `iris_two_species`, mais a malgré cela permis la conservation de toutes les modalités d'origine liées à la variable `Species` dans le jeu de données `iris`.) Par conséquent, le $d_{s}$ de Cohen de -2.10 obtenu plus haut indique que la longueur des sépals (`Sepal.Length`) pour l'espèce `setosa` est inférieure à celles des sépals de l'espèce `versicolor`. Cette interprétation devrait être en cohérence avec le graphique réalisé au préalable. Si l'on avait voulu avoir le calcul inverse (`versicolor` - `setosa`), il aurait  fallu reconfigurer l'ordre des modalités, par exemple à l'aide de la fonction `fct_relevel()` du package `forcats` comme montré à la fin du chapite 3.

Une fois que l'on a calculé une taille d'effet, il est toujours intéressant d'essayer de formuler un jugement sur l'importance, l'ampleur de l'effet. En ce sens, des valeurs seuils ont été proposées dans la littérature (Cohen, 1988; in Lakens [-@lakensCalculatingReportingEffect2013]). Ces valeurs, valables pour interpréter des tailles d'effet dans le cadre d'une étude de type *between-subject design*, sont montrées dans le tableau ci-dessous.

```{r effectsizetable, echo = FALSE}
knitr::kable(
  tribble(
    ~Petit, ~Moyen, ~Grand,
    0.2,     0.5,      0.8
  ), 
  caption = "Taille d'effet pour une différence de moyennes"
)
```

Ces valeurs sont relativement arbitraires, et l'interprétation de la taille de l'effet et des conséquences qu'il peut avoir en pratique ne devrait pas être liée de manière trop rigide à ces valeurs [@lakensCalculatingReportingEffect2013].

Il existe également une autre approche pour interpréter une valeur de taille d'effet : l'approche *Common Language explanation* [@lakensCalculatingReportingEffect2013]. Cette approche consiste à faire le lien entre la valeur de la taille d'effet et les probabilités de rencontrer des valeurs similaires ou supérieures dans les groupes comparés. Par exemple, lorsqu'on obtient un $d_{s}$ de Cohen de 0.80, cela peut se traduire par le fait qu'il y a 71.4 % de chances qu'une personne prise au hasard dans le groupe avec la meilleure moyenne ait un score plus élevé qu'une personne qui serait prise au hasard dans le groupe avec la moyenne la plus basse des deux groupes. Kristoffer Magnusson a réalisé une page web qui permet d'utiliser l'approche *Common Language explanation* pour n'importe quelle valeur de taille d'effet dans le cadre d'une étude de type *between-subject design*. Jetez un oeil ici : https://rpsychologist.com/cohend.

**gs de Hedges**

Il a été rapporté, dans la littérature, qu'en réalité le $d_{s}$ de Cohen est relativement biaisé lorsqu'il s'agit d'estimer la taille d'un effet dans la population d'intérêt à partir d'échantillons de population (autrement dit, à l'échelle de nombreux échantillons, on sait qu'avec le $d_{s}$ de Cohen on aura en moyenne un écart entre l'effet qu'on a trouvé et l'effet réel qui existe dans la population). Cela sera d'autant plus vrai lorsque les calculs seront réalisés à partir de petits échantillons ($N$ < 20), selon Hedges et Okins (1985) cités par Lakens [-@lakensCalculatingReportingEffect2013]. En raison de cela, un autre indice statistique a été proposé pour corriger cette erreur systématique qui sera d'autant plus grande que l'échantillon étudié est petit, à savoir le $g_{s}$ de Hedges :

$$g_{s} = d_{s} (1 - \frac{3}{4(N_{1} + N_{2}) - 9})$$

Dans R, le $g_{s}$ de Hedges lié à un échantillon de population peut être calculé à l'aide de la fonction `hedges_g()` du package `effectsize` :

```{r hedges g between}
hedges_g(Sepal.Length ~ Species, data = iris_two_species, paired = FALSE, pooled_sd = TRUE)
```

Ici, la valeur ne change pas beaucoup par rapport au cas précédent, car l'effectif n'est pas si petit que cela ($N_{1}$ + $N_{2}$ = 100 ici, ce qui fait que la correction appliquée au $d_{s}$ de Cohen est minime).

**Delta de Glass**

Dans certains cas où l'on souhaiterait comparer les scores de deux groupes indépendants pour tester l'effet de deux conditions expérimentales différentes, l'expérimentation en tant que telle peut influencer, au-delà de la moyenne, l'écart-type de la variable réponse dans un des deux groupes. On peut se trouver dans ce genre de situation lorsque l'on compare les données post-programme d'un groupe entrainé ou traité à celles d'un groupe contrôle. En effet, le groupe entraîné/traité peut voir son écart-type changé au terme d'un programme en raison d'une réponse individuelle hétérogène à ce programme, ce qui ne sera pas en principe le cas du groupe contrôle. Dans ce genre de situation, des indices statistiques autres que le $g_{s}$ de Hedges mériteraient d'être calculés, tels que le $\Delta$ de Glass [@lakensCalculatingReportingEffect2013] :

$$\Delta = \frac{\overline{X_{1}} - \overline{X_{2}}} {s_{2}}$$


Le calcul du $\Delta$ de Glass est dans l'idée le même que celui du $d_{s}$ de Cohen, sauf que la différence entre les moyennes des deux groupes n'est pas divisée par l'écart-type commun des deux groupes, mais par celui d'un seul des deux groupes, qui serait en principe celui qui représenterait la condition contrôle ou la condition de référence. Une pratique souvent recommandée pour comparer dans ce genre de situation les scores post-programme de deux groupes (un groupe entraîné/traité et un groupe contrôle) serait d'utiliser l'écart-type des scores du groupe contrôle obtenu en pré-programme [@lakensCalculatingReportingEffect2013]. 

Dans R, le $\Delta$ de Glass lié à un échantillon de population peut être calculé à l'aide de la fonction `glass_delta()` du package `effectsize`. Attention, l'écart-type utilisé dans le code suivant est celui de la variable quantitative associée à la modalité 2 de la variable qualitative, qui est toujours `versicolor` dans cet exemple.

```{r glass delta between}
glass_delta(Sepal.Length ~ Species, data = iris_two_species)
```


*Cas de deux groupes de données dépendants (données pairées)*

**dz et dav de Cohen**

Le calcul classique pour obtenir la taille d'effet désignant l'écart entre deux groupes de données dépendantes est celui du $d_{z}$ [@lakensCalculatingReportingEffect2013], qui est montré ci-dessous :

$$d_{z} = \frac{\overline{X} _{diff}}{s_{diff}},$$

$\overline{X} _{diff}$ désignant la moyenne des différences relatives à chaque pair de valeurs obtenues dans les deux conditions comparées, et $s_{diff}$ désignant l'écart-type de ces différences. Dans R, le $d_{z}$ peut être obtenu à nouveau avec la fonction `cohens_d()` du package `effectsize`. Pour illustrer cela, nous allons cette fois utiliser le jeu de données `Blink` associé au package `PairedData` qui doit être installé et chargé pour être utilisé. Pour information, `Blink` contient les données de taux de clignotement des yeux obtenues chez 12 sujets et dans deux conditions différentes : 1/ tâche où il fallait diriger un stylo selon une trajectoire rectiligne (modalité `Straight`) ; 2/ tâche où il fallait diriger un stylo selon une trajectoire avec des oscillations (`Oscillating`).

```{r Blink view, echo = FALSE, warning = FALSE, message=FALSE}
library(PairedData)
data(Blink)
head(Blink)
```

Pour la suite de l'analyse, on peut reconfigurer ce jeu de données de telle sorte à bien avoir les conditions testées dans une même colonne et les valeurs correspondantes dans la colonne d'à côté, avec la modalité "Straight" en tant que première modalité à considérer dans les fonctions à suivre. Le nouveau jeu de données s'appellerait alors `Blink2`.

```{r Blinkreconfiguration, echo = FALSE, message = FALSE, fig.align = "center", fig.cap="Données du jeu de données `Blink`"}
Blink2 <-
  Blink %>%
  pivot_longer(cols = c(Straight, Oscillating), names_to = "Condition", values_to = "Blink_rate") %>%
  mutate(Condition = fct_relevel(Condition, "Straight", "Oscillating"))

Blink2

ggplot(data = Blink2, aes(x = Condition, y = Blink_rate)) +
  geom_point(size = 2) +
  geom_line(aes(group = Subject)) +
  stat_summary(fun.data = "mean_sdl", fun.args = list(mult = 1), geom = "errorbar", color = "red", size = 1.2, width = 0.1) +
  stat_summary(aes(group = 1), geom = "line", color = "red", size = 1.2) +
  stat_summary(fun = "mean", geom = "point", color = "red", size = 3)
```

Dans R, on peut alors calculer $d_{z}$ à nouveau à l'aide de la fonction `cohens_d()` du package `effectsize` comme ceci :

```{r cohens dz within, warning=FALSE, message=FALSE}
cohens_d(Blink_rate ~ Condition, data = Blink2, paired = TRUE)
```

Toutefois, d'après Lakens [-@lakensCalculatingReportingEffect2013], il peut être intéressant de rapporter plutôt un indice de taille d'effet qui ne serait pas influencé par le fait que les données des deux groupes à comparer soient corrélées, notamment en vue de rendre comparable cette taille d'effet à celles obtenues dans le cadre d'études de type *between-subject design*, pour plus facilemement conduire des méta-analyses par la suite par exemple. La recommandation de Lakens [-@lakensCalculatingReportingEffect2013] serait alors d'utiliser l'indice $d_{av}$, dont le calcul serait le suivant : 

$$d_{av} = \frac{\overline{X} _{diff}}{\sqrt{\frac{s_{1}^2 + s_{2}^2} {2}}}$$

Ce calcul reviendrait donc à diviser la moyenne des différences par l'écart-type moyen relatif aux deux groupes de données. Pour obtenir $d_{av}$, il est possible de repartir de la fonction `cohens_d()` et de sa configuration pour des groupes indépendants, mais en indiquant `pooled_sd = FALSE` dans la fonction, comme ci-dessous : 

```{r cohens dav within, warning=FALSE, message=FALSE}
cohens_d(Blink_rate ~ Condition, data = Blink2, paired = FALSE, pooled_sd = FALSE)
```

En effet, que l'on fasse la moyenne des différences (ce qui serait attendu pour le présent calcul) ou la différence entre deux moyennes (ce qui est finalement fait par la fonction tel que configurée ci-dessus), cela ne change rien avec des données pairées. Le numérateur $\overline{X} _{diff}$ reste donc correctement calculé même avec cette configuration de fonction qui est faite initialement pour des groupes indépendants. Le fait d'indiquer `pooled_sd = FALSE` change le calcul du dénominateur que nous avions rencontré initialement pour le calcul de $d_{s}$, cela pour obtenir le calcul attendu pour le $d_{av}$.

**gav de Hedges**

Comme dans le cas de l'étude de groupes indépendants, $d_{av}$ et ses dérivés sont biaisés. Il peut donc être à nouveau préférable de calculer le $g_{av}$ de Hedges avec la fonction `hedges_g()` configurée comme ceci : 

```{r hedges gav within, warning=FALSE, message=FALSE}
hedges_g(Blink_rate ~ Condition, data = Blink2, paired = FALSE, pooled_sd = FALSE)
```

Toutefois, comme le rappelle Lakens [-@lakensCalculatingReportingEffect2013], le $g_{av}$ de Hedges ne serait pas complètement non biaisé.

```{r detach MASS, echo = FALSE}
detach(package:PairedData)
detach(package:MASS)
```






